"""
Матрица ошибок - это еще одно понятие из науки о данных. После того как модель обучилась предсказывать ответы,
полезно посчитать, сколько было дано верных и неверных ответов. Для этого составляют матрицу ошибок.
Для бинарного классификатора (когда ответов в модели всего два, например, дать кредит или нет)
confusion matrix представляет собой матрицу 2х2:

где:
TP - количество элементов, которые в y и y_pred равны 1;
FP - количество элементов, которые в y равны 0, в y_pred равны 1;
FN - количество элементов, которые в y равны 1, в y_pred равны 0;
TN - количество элементов, которые в y и y_pred равны 0;

В этом задании мы поработаем с настоящим классификатором. Его задача - проанализировать информацию о цветках ириса.
Вам дано n - количество элементов y и y_pred, для которых нужно составить confusion matrix.
Даны массивы y - исходные данные и y_pred - результат работы классификатора. Выведите матрицу ошибок.
Обратите внимание, что итоговый массив должен быть целочисленным.
"""
import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression

X, y = load_iris(return_X_y=True) # загрузка датасета
clf = LogisticRegression(random_state=0, max_iter=130).fit(X, y) # настройка и обучение классификатора

n = int(input())
y = y[:n] # возьмем часть правильных ответов
y_pred = clf.predict(X)[:n] # возьмем часть ответов классификатора

# TN (True Negatives): y=0 и y_pred=0
TN = np.sum((y == 0) & (y_pred == 0))

# FP (False Positives): y=0 и y_pred=1
FP = np.sum((y == 0) & (y_pred == 1))

# FN (False Negatives): y=1 и y_pred=0
FN = np.sum((y == 1) & (y_pred == 0))

# TP (True Positives): y=1 и y_pred=1
TP = np.sum((y == 1) & (y_pred == 1))

# Формирование итоговой матрицы ошибок 2x2
# обратите внимание, что порядок элементов в матрице ошибок специфичен для задачи
confusion_matrix = np.array([
    [TN, FP],
    [FN, TP]
])

print(confusion_matrix)
