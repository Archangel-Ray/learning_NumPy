"""
В нейронных сетях есть понятие функции активации.
Это функция, которая в зависимости от значения нейрона принимает решение дать тот или иной ответ.

ReLU - одна из таких функций. Ее задача очень простая - заменять отрицательные значения на 0.
Формально это можно описать так:

Ri=max(xi,0)
Ri=max(xi,0)
где:

Ri - значение функции активации ReLU для i-того нейрона
xi - значение i-того нейрона

Вводится массив значений нейронов, длина этого массива всегда равна 7. Выведите для него результат применения ReLU
"""
import numpy as np

arr = np.array([float(input()) for _ in range(7)])
res = np.maximum(arr, 0)
print(res)
